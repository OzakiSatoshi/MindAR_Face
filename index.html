<html>
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <script src="https://aframe.io/releases/1.5.0/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mind-ar@1.2.5/dist/mindar-face-aframe.prod.js"></script>
    <style>
      .a-canvas {
        z-index: 0 !important;
        position: absolute !important;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
      }

      .logo {
        position: absolute;
        bottom: 10px;
        left: 50%;
        transform: translateX(-50%);
        z-index: 9999 !important;
        pointer-events: none;
      }
      .logo img {
        max-width: 150px;
        width: 30%;
        height: auto;
      }

      #capture-btn {
        position: absolute;
        bottom: 10px;
        left: 10px;
        z-index: 10000 !important;
        padding: 10px;
        background-color: transparent;
        border: none;
        cursor: pointer;
      }

      @media (max-width: 768px) {
        .logo img {
          max-width: 100px;
        }
        #capture-btn {
          width: 60px;
          height: 60px;
          bottom: 20px;
        }
      }
    </style>
  </head>

  <body>
    <!-- カメラ映像を表示するためのvideo要素 -->
    <video id="video" autoplay playsinline style="display:none;"></video>

    <a-scene mindar-face embedded color-space="sRGB" 
             renderer="colorManagement: true, alpha: true" 
             vr-mode-ui="enabled: false" 
             device-orientation-permission-ui="enabled: false">
      <a-assets>
        <a-asset-item id="glassesModel" src="https://cdn.jsdelivr.net/gh/hiukim/mind-ar-js@1.2.5/examples/face-tracking/assets/glasses/scene.gltf"></a-asset-item>
      </a-assets>

      <a-camera active="false" position="0 0 0"></a-camera>

      <a-entity mindar-face-target="anchorIndex: 168">
        <a-gltf-model rotation="0 0 0" position="0 0 0" scale="0.01 0.01 0.01" src="#glassesModel"></a-gltf-model>
      </a-entity>
    </a-scene>

      <img id="logo-img" src="./Logo%26Font_BackAlpha.png" alt="Company Logo" style="width :100%; height:100%;">
    </div>

    <button id="capture-btn">
      <img src="./shutter.png" alt="Shutter Button" style="width:100%; height:100%;">
    </button>

    <canvas id="arCanvas" style="display:none;"></canvas>

    <script>
      const captureBtn = document.getElementById('capture-btn');
      const canvas = document.getElementById('arCanvas');
      const video = document.getElementById('video');
      const scene = document.querySelector('a-scene');
      const logoImg = document.getElementById('logo-img');

      // カメラ映像の取得
      navigator.mediaDevices.getUserMedia({ video: true })
        .then((stream) => {
          video.srcObject = stream;
        })
        .catch((error) => {
          console.error('Error accessing the camera', error);
        });

      // WebGLの描画バッファを取得し、そのデータをImageDataに変換して描画する関数
      function captureWebGLToImageData(renderer) {
        try {
          const gl = renderer.getContext();
          const width = gl.drawingBufferWidth;
          const height = gl.drawingBufferHeight;

          // WebGLの描画バッファからピクセルデータを取得
          const pixels = new Uint8Array(width * height * 4);
          gl.readPixels(0, 0, width, height, gl.RGBA, gl.UNSIGNED_BYTE, pixels);

          // WebGLのピクセルデータをImageDataに変換
          const imageData = new ImageData(new Uint8ClampedArray(pixels), width, height);

          return imageData;  // ImageDataオブジェクトを返す
        } catch (error) {
          console.error("Error during WebGL buffer capture", error);
          return null;
        }
      }

      // WebGLコンテンツとカメラ映像を合成してキャンバスに描画する関数
      function renderCombinedScene(renderer, canvas, video) {
        try {
          // WebGLの描画バッファをImageDataに変換
          const imageData = captureWebGLToImageData(renderer);

          if (!imageData) {
            throw new Error("Failed to capture WebGL content.");
          }

          const width = imageData.width;
          const height = imageData.height;

          // 一時キャンバスを作成してWebGLとカメラ映像を合成
          const tempCanvas = document.createElement('canvas');
          tempCanvas.width = width;
          tempCanvas.height = height;
          const tempContext = tempCanvas.getContext('2d');

          // カメラ映像を描画
          tempContext.drawImage(video, 0, 0, width, height);

          // WebGLの内容を反転して描画
          tempContext.save();
          tempContext.scale(1, -1);  // Y軸を反転
          tempContext.putImageData(imageData, 0, -height);
          tempContext.restore();

          // 最終的にメインキャンバスに合成
          const context = canvas.getContext('2d');
          canvas.width = width;
          canvas.height = height;
          context.drawImage(tempCanvas, 0, 0);

        } catch (error) {
          console.error("Error during scene capture", error);
        }
      }

      // 撮影ボタンを押した際に現在のカメラ映像とAR表示をキャプチャする機能
      captureBtn.addEventListener('click', () => {
        if (video.readyState === video.HAVE_ENOUGH_DATA) {
          const renderer = scene.renderer;

          if (renderer && scene.camera) {
            requestAnimationFrame(() => {
              try {
                // ARオブジェクトをレンダリング
                renderer.render(scene.object3D, scene.camera);  

                // WebGLとカメラ映像を合成して描画
                renderCombinedScene(renderer, canvas, video);

                // ロゴをキャンバスに描画（中央に配置）
                const context = canvas.getContext('2d');
                const logoWidth = logoImg.width;
                const logoHeight = logoImg.height;
                const x = (canvas.width - logoWidth) / 2;
                const y = (canvas.height - logoHeight) / 2;
                context.drawImage(logoImg, x, y);

                // キャプチャ画像を生成してダウンロード
                const imageData = canvas.toDataURL('image/png');
                const link = document.createElement('a');
                link.href = imageData;
                link.download = 'capture.png';
                link.click();
              } catch (error) {
                console.error("Render error:", error);
              }
            });
          } else {
            console.error("Renderer or camera is not available for rendering.");
          }
        } else {
          console.log("Waiting for video data...");
        }
      });
          
    </script>
  </body>
</html>