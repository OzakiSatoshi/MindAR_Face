<!DOCTYPE html>
<html>
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <script src="https://aframe.io/releases/1.5.0/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mind-ar@1.2.5/dist/mindar-face-aframe.prod.js"></script>
    <style>
      html, body {
        margin: 0;
        padding: 0;
        width: 100%;
        height: 100%;
        overflow: hidden;
      }

      .a-canvas {
        z-index: 0 !important;
        position: absolute !important;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
      }

      .logo {
        position: absolute;
        bottom: 10px;
        left: 50%;
        transform: translateX(-50%);
        z-index: 9999 !important;
        pointer-events: none;
      }
      .logo img {
        max-width: 150px;
        width: 30%;
        height: auto;
      }

      #capture-btn {
        position: absolute;
        bottom: 10px;
        left: 10px;
        z-index: 10000 !important;
        padding: 10px;
        background-color: transparent;
        border: none;
        cursor: pointer;
      }

      @media (max-width: 768px) {
        .logo img {
          max-width: 100px;
        }
        #capture-btn {
          width: 60px;
          height: 60px;
          bottom: 20px;
        }
      }

      a-scene {
        width: 100%;
        height: 100%;
        position: absolute;
        top: 0;
        left: 0;
      }
    </style>
  </head>

  <body>
    <!-- カメラ映像を表示するためのvideo要素 -->
    <video id="video" autoplay playsinline style="display:none;"></video>

    <a-scene mindar-face embedded color-space="sRGB"
             renderer="colorManagement: true, alpha: true"
             vr-mode-ui="enabled: false"
             device-orientation-permission-ui="enabled: false">
      <a-assets>
        <a-asset-item id="glassesModel" src="https://cdn.jsdelivr.net/gh/hiukim/mind-ar-js@1.2.5/examples/face-tracking/assets/glasses/scene.gltf"></a-asset-item>
      </a-assets>

      <a-camera active="false" position="0 0 0"></a-camera>

      <a-entity mindar-face-target="anchorIndex: 168">
        <a-gltf-model rotation="0 0 0" position="0 0 0" scale="0.01 0.01 0.01" src="#glassesModel"></a-gltf-model>
      </a-entity>
    </a-scene>

    <div class="logo">
      <img id="logo-img" src="./Logo%26Font_BackAlpha.png" alt="Company Logo">
    </div>

    <button id="capture-btn">
      <img src="./shutter.png" alt="Shutter Button" style="width:100%; height:100%;">
    </button>

    <canvas id="arCanvas" style="display:none;"></canvas>

    <script>
      const captureBtn = document.getElementById('capture-btn');
      const canvas = document.getElementById('arCanvas');
      const video = document.getElementById('video');
      const scene = document.querySelector('a-scene');
      const logoImg = document.getElementById('logo-img');

      // カメラ映像の取得
      navigator.mediaDevices.getUserMedia({ video: true })
        .then((stream) => {
          video.srcObject = stream;
        })
        .catch((error) => {
          console.error('Error accessing the camera', error);
        });

      // WebGLとカメラ映像を合成して描画するための関数
      function captureWebGLAndVideo(renderer, canvas) {
          try {
              const gl = renderer.getContext();
              const width = gl.drawingBufferWidth;
              const height = gl.drawingBufferHeight;

              // メインキャンバスの設定
              canvas.width = width;
              canvas.height = height;
              const context = canvas.getContext('2d');

              // カメラ映像を描画（反転なし）
              context.drawImage(video, 0, 0, width, height);

              // WebGLコンテンツを取得
              const pixels = new Uint8Array(width * height * 4);
              gl.readPixels(0, 0, width, height, gl.RGBA, gl.UNSIGNED_BYTE, pixels);

              // WebGLのピクセルデータをImageDataに変換
              const imageData = new ImageData(new Uint8ClampedArray(pixels), width, height);

              // 一時キャンバスにWebGLコンテンツを描画
              const tempCanvas = document.createElement('canvas');
              tempCanvas.width = width;
              tempCanvas.height = height;
              const tempContext = tempCanvas.getContext('2d');

              tempContext.putImageData(imageData, 0, 0);
              context.drawImage(tempCanvas, 0, 0);
          } catch (error) {
              console.error("Error during WebGL and video capture", error);
          }
      }

      // 撮影ボタンを押した際に現在のカメラ映像とAR表示をキャプチャする機能
      captureBtn.addEventListener('click', () => {
        if (video.readyState === video.HAVE_ENOUGH_DATA) {
          const renderer = scene.renderer;

          if (renderer && scene.camera) {
            requestAnimationFrame(() => {
              try {
                // WebGLとカメラ映像を合成して描画
                captureWebGLAndVideo(renderer, canvas);

                // ロゴをキャンバスに描画（中央に配置）
                const context = canvas.getContext('2d');
                const logoWidth = logoImg.width;
                const logoHeight = logoImg.height;
                const x = (canvas.width - logoWidth) / 2;
                const y = (canvas.height - logoHeight) / 2;
                context.drawImage(logoImg, x, y);

                // キャプチャ画像を生成してダウンロード
                const imageData = canvas.toDataURL('image/png');
                const link = document.createElement('a');
                link.href = imageData;
                link.download = 'capture.png';
                link.click();
              } catch (error) {
                console.error("Render error:", error);
              }
            });
          } else {
            console.error("Renderer or camera is not available for rendering.");
          }
        } else {
          console.log("Waiting for video data...");
        }
      });
    </script>
  </body>
</html>
