<html>
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <script src="https://aframe.io/releases/1.5.0/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mind-ar@1.2.5/dist/mindar-face-aframe.prod.js"></script>
    <style>
      .a-canvas {
        z-index: 0 !important;
        position: absolute !important;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
      }

      .logo {
        position: absolute;
        bottom: 10px;
        left: 50%;
        transform: translateX(-50%);
        z-index: 9999 !important;
        pointer-events: none;
      }
      .logo img {
        max-width: 150px;
        width: 30%;
        height: auto;
      }

      #capture-btn {
        position: absolute;
        bottom: 10px;
        left: 10px;
        z-index: 10000 !important;
        padding: 10px;
        background-color: transparent;
        border: none;
        cursor: pointer;
      }

      @media (max-width: 768px) {
        .logo img {
          max-width: 100px;
        }
        #capture-btn {
          width: 60px;
          height: 60px;
          bottom: 20px;
        }
      }
    </style>
  </head>

  <body>
    <!-- カメラ映像を表示するためのvideo要素 -->
    <video id="video" autoplay playsinline style="display:none;"></video>

    <a-scene mindar-face embedded color-space="sRGB" 
             renderer="colorManagement: true, alpha: true" 
             vr-mode-ui="enabled: false" 
             device-orientation-permission-ui="enabled: false">
      <a-assets>
        <a-asset-item id="glassesModel" src="https://cdn.jsdelivr.net/gh/hiukim/mind-ar-js@1.2.5/examples/face-tracking/assets/glasses/scene.gltf"></a-asset-item>
      </a-assets>

      <a-camera active="false" position="0 0 0"></a-camera>

      <a-entity mindar-face-target="anchorIndex: 168">
        <a-gltf-model rotation="0 0 0" position="0 0 0" scale="0.01 0.01 0.01" src="#glassesModel"></a-gltf-model>
      </a-entity>
    </a-scene>

    <div class="logo">
      <img id="logo-img" src="./Logo%26Font_BackAlpha.png" alt="Company Logo">
    </div>

    <button id="capture-btn">
      <img src="./shutter.png" alt="Shutter Button" style="width:100%; height:100%;">
    </button>

    <canvas id="arCanvas" style="display:none;"></canvas>

    <script>
      const captureBtn = document.getElementById('capture-btn');
      const canvas = document.getElementById('arCanvas');
      const video = document.getElementById('video');
      const scene = document.querySelector('a-scene');
      const logoImg = document.getElementById('logo-img');

      // カメラ映像の取得
      navigator.mediaDevices.getUserMedia({ video: true })
        .then((stream) => {
          video.srcObject = stream;
        })
        .catch((error) => {
          console.error('Error accessing the camera', error);
        });

      // キャプチャボタンのイベントリスナーを修正
      captureBtn.addEventListener('click', async () => {
        if (video.readyState === video.HAVE_ENOUGH_DATA) {
          const renderer = scene.renderer;

          if (renderer && scene.camera) {
            // ロゴ画像の読み込みを待つ
            await new Promise((resolve) => {
              if (logoImg.complete) {
                resolve();
              } else {
                logoImg.onload = resolve;
              }
            });

            // MindARのレンダリングサイクルと同期を取る
            scene.renderer.setAnimationLoop(() => {
              try {
                const gl = renderer.getContext();
                const width = gl.drawingBufferWidth;
                const height = gl.drawingBufferHeight;

                canvas.width = width;
                canvas.height = height;
                const context = canvas.getContext('2d');

                // カメラ映像を描画
                context.drawImage(video, 0, 0, width, height);

                // WebGLの内容を取得
                const pixels = new Uint8Array(width * height * 4);
                gl.readPixels(0, 0, width, height, gl.RGBA, gl.UNSIGNED_BYTE, pixels);

                // 一時キャンバスを作成してWebGL内容を描画
                const tempCanvas = document.createElement('canvas');
                tempCanvas.width = width;
                tempCanvas.height = height;
                const tempContext = tempCanvas.getContext('2d');
                const imageData = new ImageData(new Uint8ClampedArray(pixels), width, height);

                // WebGL内容を反転して描画
                tempContext.putImageData(imageData, 0, 0);
                tempContext.scale(1, -1);
                tempContext.drawImage(tempCanvas, 0, -height);

                // メインキャンバスに合成
                context.drawImage(tempCanvas, 0, 0);

                // ロゴを中央に描画
                const logoWidth = Math.min(150, width * 0.3); // 最大幅を制限
                const logoHeight = (logoWidth / logoImg.width) * logoImg.height;
                const x = (width - logoWidth) / 2;
                const y = height - logoHeight - 10; // 下部に配置
                context.drawImage(logoImg, x, y, logoWidth, logoHeight);

                // キャプチャ画像を生成してダウンロード
                const imageData = canvas.toDataURL('image/png');
                const link = document.createElement('a');
                link.href = imageData;
                link.download = 'capture.png';
                link.click();

                // キャプチャ後にアニメーションループを停止
                scene.renderer.setAnimationLoop(null);
              } catch (error) {
                console.error("Render error:", error);
                scene.renderer.setAnimationLoop(null);
              }
            });
          } else {
            console.error("Renderer or camera is not available for rendering.");
          }
        } else {
          console.log("Waiting for video data...");
        }
      });
    </script>
  </body>
</html>
